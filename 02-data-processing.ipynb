{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "df = pd.read_csv('ds_salaries.csv')\n",
    "df = df.iloc[:, 1:] # exclude 1st (0th) column in the dataset\n",
    "X = df.iloc[:, [0,1,2,3,5,8,9,10]].values # independent variables aka features\n",
    "y = df.iloc[:, 6].values # predict salary_in_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(607, 8)\n",
      "[[2020 'MI' 'FT' ... 0 'DE' 'L']\n",
      " [2020 'SE' 'FT' ... 0 'JP' 'S']\n",
      " [2020 'SE' 'FT' ... 50 'GB' 'M']\n",
      " ...\n",
      " [2022 'SE' 'FT' ... 0 'US' 'M']\n",
      " [2022 'SE' 'FT' ... 100 'US' 'M']\n",
      " [2022 'MI' 'FT' ... 100 'US' 'L']]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(607,)\n",
      "[ 79833 260000 109024  20000 150000  72000 190000  35735 135000 125000]\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(X[:, [-3]]) # impute numerical cols\n",
    "X[:, [-3]] = imputer.transform(X[:, [-3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2020 'MI' 'FT' ... 0.0 'DE' 'L']\n",
      " [2020 'SE' 'FT' ... 0.0 'JP' 'S']\n",
      " [2020 'SE' 'FT' ... 50.0 'GB' 'M']\n",
      " ...\n",
      " [2022 'SE' 'FT' ... 0.0 'US' 'M']\n",
      " [2022 'SE' 'FT' ... 100.0 'US' 'M']\n",
      " [2022 'MI' 'FT' ... 100.0 'US' 'L']]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DE</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Scientist</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>JP</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>GBP</td>\n",
       "      <td>50.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Product Data Analyst</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>USD</td>\n",
       "      <td>50.0</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2                           3    4     5   6  7\n",
       "0  2020  MI  FT              Data Scientist  EUR   0.0  DE  L\n",
       "1  2020  SE  FT  Machine Learning Scientist  USD   0.0  JP  S\n",
       "2  2020  SE  FT           Big Data Engineer  GBP  50.0  GB  M\n",
       "3  2020  MI  FT        Product Data Analyst  USD   0.0  HN  S\n",
       "4  2020  SE  FT   Machine Learning Engineer  USD  50.0  US  L"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# drop='first' drop the first category in each feature to avoid dummy trap\n",
    "# (eliminate collinearity)\n",
    "# remainder=\"passthrough\" allows non-specified columns to be kept. Default is \"drop\"\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(categories='auto',drop='first'), [1,2])], remainder='passthrough') \n",
    "X = ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(607, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>EUR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DE</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>Machine Learning Scientist</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>JP</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>GBP</td>\n",
       "      <td>50.0</td>\n",
       "      <td>GB</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>Product Data Analyst</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>USD</td>\n",
       "      <td>50.0</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5     6                           7    8     9   \\\n",
       "0  0.0  1.0  0.0  0.0  1.0  0.0  2020              Data Scientist  EUR   0.0   \n",
       "1  0.0  0.0  1.0  0.0  1.0  0.0  2020  Machine Learning Scientist  USD   0.0   \n",
       "2  0.0  0.0  1.0  0.0  1.0  0.0  2020           Big Data Engineer  GBP  50.0   \n",
       "3  0.0  1.0  0.0  0.0  1.0  0.0  2020        Product Data Analyst  USD   0.0   \n",
       "4  0.0  0.0  1.0  0.0  1.0  0.0  2020   Machine Learning Engineer  USD  50.0   \n",
       "\n",
       "   10 11  \n",
       "0  DE  L  \n",
       "1  JP  S  \n",
       "2  GB  M  \n",
       "3  HN  S  \n",
       "4  US  L  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "pd.DataFrame(X).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use LabelEncoder. WE won't do that here\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# le = LabelEncoder()\n",
    "# y = le.fit_transform(y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(485, 12)\n",
      "[[0.0 1.0 0.0 ... 50.0 'CA' 'L']\n",
      " [0.0 0.0 1.0 ... 100.0 'US' 'L']\n",
      " [0.0 0.0 1.0 ... 100.0 'US' 'M']\n",
      " ...\n",
      " [0.0 0.0 0.0 ... 50.0 'GB' 'L']\n",
      " [0.0 1.0 0.0 ... 0.0 'US' 'S']\n",
      " [0.0 0.0 0.0 ... 50.0 'US' 'L']]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 12)\n",
      "[[0.0 0.0 0.0 ... 50.0 'DE' 'S']\n",
      " [0.0 1.0 0.0 ... 100.0 'ES' 'M']\n",
      " [0.0 1.0 0.0 ... 100.0 'US' 'L']\n",
      " ...\n",
      " [0.0 0.0 1.0 ... 0.0 'US' 'L']\n",
      " [0.0 0.0 0.0 ... 100.0 'US' 'L']\n",
      " [0.0 1.0 0.0 ... 100.0 'IR' 'M']]\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train[:, 6:] = sc.fit_transform(X_train[:, 6:])\n",
    "X_test[:, 6:] = sc.transform(X_test[:, 6:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.18 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.18 (default, Jul  1 2022, 12:27:04) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
